{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction<a id=\"10\"></a>\n",
    "\n",
    "This competition requires us to predict future sales for Russian firm 1C Company. Our submission will contain next month sales predictions for 5100 items at each of 42 shops, with predictions being clipped into the range (0,20). The performance metric is RMSE. To inform these predictions we are given sales data covering the 33 months prior to the test period. For the (shop,item) pairs we are trying to predict, the following possibilities exist:\n",
    "1. This pair exists in our training set\n",
    "2. The item is in our training set, but not with the shop\n",
    "3. The item is not in our training set at all\n",
    "\n",
    "Our model needs to be capable of making predictions in all three cases.\n",
    "\n",
    "**Attached datasets**\n",
    "\n",
    "I initially used previously uploaded datasets containing english translations of item/category/shop names. I found that item names in those datasets had not been translated in their entirety, so I have attached an english translated dataset with complete translations. \n",
    "\n",
    "I have also attached a dataset which contains the dataframe our initial model is trained with and the initial model itself. These can be loaded to skip directly to modelling with the dataset or exploring the model's predictions.\n",
    "\n",
    "**Contents**\n",
    "\n",
    "Multiple other notebooks have already done an excellent job covering EDA, such as [this notebook](https://www.kaggle.com/kyakovlev/1st-place-solution-part-1-hands-on-data/) by the holder of the current 4th place leaderboard submission.\n",
    "\n",
    "[1. Introduction](#10)  \n",
    "[2. Preparing Dataset](#20)  \n",
    "&nbsp;&nbsp;[2.1 Preparing Item/Category Information](#21)  \n",
    "&nbsp;&nbsp;[2.2 Preparing Sales Information](#22)  \n",
    "&nbsp;&nbsp;[2.3 Constructing Training Dataframe](#23)  \n",
    "&nbsp;&nbsp;[2.4 Adding Shop Information](#24)  \n",
    "&nbsp;&nbsp;[2.5 Ages & Aggregating Sales/Price information](#25)  \n",
    "&nbsp;&nbsp;[2.6 Lagging Values & Features that use Prior Information](#26)  \n",
    "&nbsp;&nbsp;[2.7 Encoding Name Information](#27)  \n",
    "[3. Modelling](#30)  \n",
    "&nbsp;&nbsp;[3.1 Training Model](#31)  \n",
    "&nbsp;&nbsp;[3.2 Submitting](#32)  \n",
    "[4. Analysing Model Output](#40)  \n",
    "&nbsp;&nbsp;[4.1 Plots](#41)  \n",
    "&nbsp;&nbsp;[4.2 Table Views](#42) \n",
    "\n",
    "**Results**\n",
    "\n",
    "This notebook has a submission attached which achieves a leaderboard score of 0.85389. Using this submission as a base to improve on by incorporating findings gleaned in [Section 4](#40) allowed me to achieve a leaderboard score of 0.82501.\n",
    "![Leaderboard at time of posting](https://i.imgur.com/GiMxp8O.png)\n",
    "\n",
    "Leave a comment if the code is insufficiently explained at any point or you find any errors, and good luck with your own attempts! üëç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from collections import Counter\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "import category_encoders as ce\n",
    "import warnings\n",
    "\n",
    "pd.set_option('display.max_rows', 400)\n",
    "pd.set_option('display.max_columns', 160)\n",
    "pd.set_option('display.max_colwidth', 40)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preparing Training Dataset & Feature Engineering<a id=\"20\"></a>\n",
    "\n",
    "[1. Introduction](#10)  \n",
    "[2. Preparing Dataset](#20)  \n",
    "&nbsp;&nbsp;[2.1 Preparing Item/Category Information](#21)  \n",
    "&nbsp;&nbsp;[2.2 Preparing Sales Information](#22)  \n",
    "&nbsp;&nbsp;[2.3 Constructing Training Dataframe](#23)  \n",
    "&nbsp;&nbsp;[2.4 Adding Shop Information](#24)  \n",
    "&nbsp;&nbsp;[2.5 Ages & Aggregating Sales/Price information](#25)  \n",
    "&nbsp;&nbsp;[2.6 Lagging Values & Features that use Prior Information](#26)  \n",
    "&nbsp;&nbsp;[2.7 Encoding Name Information](#27)  \n",
    "[3. Modelling](#30)  \n",
    "&nbsp;&nbsp;[3.1 Training Model](#31)  \n",
    "&nbsp;&nbsp;[3.2 Submitting](#32)  \n",
    "[4. Analysing Model Output](#40)  \n",
    "&nbsp;&nbsp;[4.1 Plots](#41)  \n",
    "&nbsp;&nbsp;[4.2 Table Views](#42)  \n",
    "\n",
    "We'll be using shortened column names in this notebook to save some keystrokes and display more compactly. The submission file must name the target value 'item_cnt_month', but all sales data we work with will be monthly unless otherwise specified, so we will use 'item_cnt' until submission. The translated files already use category_id in place of item_category_id etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the test set now as we'll soon be making use of the shop_id and item_id values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  shop_id  item_id\n",
       "0   0        5     5037\n",
       "1   1        5     5320\n",
       "2   2        5     5233\n",
       "3   3        5     5232\n",
       "4   4        5     5268"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('input/test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 Preparing Item/Category Information** <a id=\"21\"></a>\n",
    "\n",
    "We load categories.csv and display the category names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PC - Headsets / Headphones</td>\n",
       "      <td>Accessories - PS2</td>\n",
       "      <td>Accessories - PS3</td>\n",
       "      <td>Accessories - PS4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accessories - PSP</td>\n",
       "      <td>Accessories - PSVita</td>\n",
       "      <td>Accessories - XBOX 360</td>\n",
       "      <td>Accessories - XBOX ONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tickets (Digital)</td>\n",
       "      <td>Delivery of goods</td>\n",
       "      <td>Game consoles - PS2</td>\n",
       "      <td>Game consoles - PS3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Game consoles - PS4</td>\n",
       "      <td>Game consoles - PSP</td>\n",
       "      <td>Game consoles - PSVita</td>\n",
       "      <td>Game consoles - XBOX 360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Game consoles - XBOX ONE</td>\n",
       "      <td>Game consoles - Others</td>\n",
       "      <td>Games - PS2</td>\n",
       "      <td>Games - PS3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Games - PS4</td>\n",
       "      <td>Games - PSP</td>\n",
       "      <td>Games - PSVita</td>\n",
       "      <td>Games - XBOX 360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Games - XBOX ONE</td>\n",
       "      <td>Games - Game accessories</td>\n",
       "      <td>Android games - Number</td>\n",
       "      <td>MAC Games - Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PC Games - Additional Editions</td>\n",
       "      <td>PC Games - Collector's Editions</td>\n",
       "      <td>PC Games - Standard Editions</td>\n",
       "      <td>PC Games - Digital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Payment Cards (Cinema, Music, Games)</td>\n",
       "      <td>Payment Cards - Live!</td>\n",
       "      <td>Payment Cards - Live! (Digital)</td>\n",
       "      <td>Payment cards - PSN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Payment cards - Windows (Digital)</td>\n",
       "      <td>Cinema - Blu-Ray</td>\n",
       "      <td>Cinema - Blu-Ray 3D</td>\n",
       "      <td>Cinema - Blu-Ray 4K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cinema - DVD</td>\n",
       "      <td>Cinema - Collector's</td>\n",
       "      <td>Books - Artbooks, encyclopedias</td>\n",
       "      <td>Books - Audiobooks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Books - Audiobooks (Digit)</td>\n",
       "      <td>Books - Audiobooks 1C</td>\n",
       "      <td>Books - Business literature</td>\n",
       "      <td>Books - Comics, manga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Books - Computer literature</td>\n",
       "      <td>Books - Methodological materials 1C</td>\n",
       "      <td>Books - Postcards</td>\n",
       "      <td>Books - Cognitive literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Books - Guides</td>\n",
       "      <td>Books - Fiction</td>\n",
       "      <td>Books - Digital</td>\n",
       "      <td>Music - CD of local production</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Music - CD of corporate production</td>\n",
       "      <td>Music - MP3</td>\n",
       "      <td>Music - Vinyl</td>\n",
       "      <td>Music - Music video</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Music - Gift editions</td>\n",
       "      <td>Gifts - Attributes</td>\n",
       "      <td>Gifts - Gadgets, robots , sports</td>\n",
       "      <td>Gifts - Soft toys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Gifts - Board games</td>\n",
       "      <td>Gifts - Board games (compact)</td>\n",
       "      <td>Gifts - Cards, stickers</td>\n",
       "      <td>Gifts - Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Gifts - Certificates, services</td>\n",
       "      <td>Gifts - Souvenirs</td>\n",
       "      <td>Gifts - Souvenirs (hinged)</td>\n",
       "      <td>Gifts - Bags, Albums, Mousepads</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Gifts - Figures</td>\n",
       "      <td>Programs - 1C: Enterprise 8</td>\n",
       "      <td>Programs - MAC (Digit)</td>\n",
       "      <td>Programs - For home and office</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Programs - For home and office (Digit)</td>\n",
       "      <td>Programs - Educational</td>\n",
       "      <td>Programs - Educational (Digit)</td>\n",
       "      <td>Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Service - Tickets</td>\n",
       "      <td>Blank media (spire)</td>\n",
       "      <td>Blank media (piece)</td>\n",
       "      <td>Batteries</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          0  \\\n",
       "0                PC - Headsets / Headphones   \n",
       "1                         Accessories - PSP   \n",
       "2                         Tickets (Digital)   \n",
       "3                       Game consoles - PS4   \n",
       "4                  Game consoles - XBOX ONE   \n",
       "5                               Games - PS4   \n",
       "6                          Games - XBOX ONE   \n",
       "7            PC Games - Additional Editions   \n",
       "8      Payment Cards (Cinema, Music, Games)   \n",
       "9         Payment cards - Windows (Digital)   \n",
       "10                             Cinema - DVD   \n",
       "11               Books - Audiobooks (Digit)   \n",
       "12              Books - Computer literature   \n",
       "13                           Books - Guides   \n",
       "14       Music - CD of corporate production   \n",
       "15                    Music - Gift editions   \n",
       "16                      Gifts - Board games   \n",
       "17           Gifts - Certificates, services   \n",
       "18                          Gifts - Figures   \n",
       "19   Programs - For home and office (Digit)   \n",
       "20                        Service - Tickets   \n",
       "\n",
       "                                       1                                  2  \\\n",
       "0                      Accessories - PS2                  Accessories - PS3   \n",
       "1                   Accessories - PSVita             Accessories - XBOX 360   \n",
       "2                      Delivery of goods                Game consoles - PS2   \n",
       "3                    Game consoles - PSP             Game consoles - PSVita   \n",
       "4                 Game consoles - Others                        Games - PS2   \n",
       "5                            Games - PSP                     Games - PSVita   \n",
       "6               Games - Game accessories             Android games - Number   \n",
       "7        PC Games - Collector's Editions       PC Games - Standard Editions   \n",
       "8                  Payment Cards - Live!    Payment Cards - Live! (Digital)   \n",
       "9                       Cinema - Blu-Ray                Cinema - Blu-Ray 3D   \n",
       "10                  Cinema - Collector's   Books - Artbooks, encyclopedias    \n",
       "11                 Books - Audiobooks 1C        Books - Business literature   \n",
       "12   Books - Methodological materials 1C                  Books - Postcards   \n",
       "13                       Books - Fiction                    Books - Digital   \n",
       "14                           Music - MP3                      Music - Vinyl   \n",
       "15                    Gifts - Attributes   Gifts - Gadgets, robots , sports   \n",
       "16         Gifts - Board games (compact)            Gifts - Cards, stickers   \n",
       "17                     Gifts - Souvenirs         Gifts - Souvenirs (hinged)   \n",
       "18           Programs - 1C: Enterprise 8             Programs - MAC (Digit)   \n",
       "19                Programs - Educational     Programs - Educational (Digit)   \n",
       "20                   Blank media (spire)               Blank media (piece)    \n",
       "\n",
       "                                   3  \n",
       "0                  Accessories - PS4  \n",
       "1             Accessories - XBOX ONE  \n",
       "2                Game consoles - PS3  \n",
       "3           Game consoles - XBOX 360  \n",
       "4                        Games - PS3  \n",
       "5                   Games - XBOX 360  \n",
       "6                 MAC Games - Number  \n",
       "7                 PC Games - Digital  \n",
       "8                Payment cards - PSN  \n",
       "9                Cinema - Blu-Ray 4K  \n",
       "10                Books - Audiobooks  \n",
       "11             Books - Comics, manga  \n",
       "12      Books - Cognitive literature  \n",
       "13    Music - CD of local production  \n",
       "14               Music - Music video  \n",
       "15                 Gifts - Soft toys  \n",
       "16               Gifts - Development  \n",
       "17   Gifts - Bags, Albums, Mousepads  \n",
       "18    Programs - For home and office  \n",
       "19                           Service  \n",
       "20                         Batteries  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = pd.read_csv('input/categories.csv')\n",
    "pd.DataFrame(categories.category_name.values.reshape(-1, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all category names have a '-' between the main category and the subcategory. We create groups by extracting the part of the name prior to a non-letter character. We then create a group_id column by label encoding the group names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_name</th>\n",
       "      <th>category_id</th>\n",
       "      <th>group_name</th>\n",
       "      <th>group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Gifts - Attributes</td>\n",
       "      <td>61</td>\n",
       "      <td>Gifts</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Games - PS3</td>\n",
       "      <td>19</td>\n",
       "      <td>Games</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Service</td>\n",
       "      <td>79</td>\n",
       "      <td>Service</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Books - Audiobooks (Digit)</td>\n",
       "      <td>44</td>\n",
       "      <td>Books</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Books - Artbooks, encyclopedias</td>\n",
       "      <td>42</td>\n",
       "      <td>Books</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        category_name  category_id group_name  group_id\n",
       "61                 Gifts - Attributes           61      Gifts         9\n",
       "19                        Games - PS3           19      Games         8\n",
       "79                            Service           79    Service        17\n",
       "44         Books - Audiobooks (Digit)           44      Books         4\n",
       "42   Books - Artbooks, encyclopedias            42      Books         4"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create broader category groupings\n",
    "categories['group_name'] = categories['category_name'].str.extract(r'(^[\\w\\s]*)')\n",
    "categories['group_name'] = categories['group_name'].str.strip()\n",
    "#label encode group names\n",
    "categories['group_id']  = le.fit_transform(categories.group_name.values)\n",
    "categories.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load items.csv, clean the name column, create multiple features based on the cleaned name, and use label encoding. The categories dataframe is then joined to the items dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    item_id  category_id                                item_name\n",
      "48       48           57  100 best works of Vivaldi (mp3-CD) (...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_name_first4</th>\n",
       "      <th>item_name_first6</th>\n",
       "      <th>item_name_first11</th>\n",
       "      <th>category_name</th>\n",
       "      <th>group_name</th>\n",
       "      <th>group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19287</th>\n",
       "      <td>19287</td>\n",
       "      <td>55</td>\n",
       "      <td>sat   best songs   pop chanson</td>\n",
       "      <td>2889</td>\n",
       "      <td>5162</td>\n",
       "      <td>9248</td>\n",
       "      <td>Music - CD of local production</td>\n",
       "      <td>Music</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5883</th>\n",
       "      <td>5883</td>\n",
       "      <td>19</td>\n",
       "      <td>prince   persia    forgotten sands  ...</td>\n",
       "      <td>2618</td>\n",
       "      <td>4703</td>\n",
       "      <td>8449</td>\n",
       "      <td>Games - PS3</td>\n",
       "      <td>Games</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16168</th>\n",
       "      <td>16168</td>\n",
       "      <td>64</td>\n",
       "      <td>board game munchkin  art 1938</td>\n",
       "      <td>521</td>\n",
       "      <td>909</td>\n",
       "      <td>1596</td>\n",
       "      <td>Gifts - Board games</td>\n",
       "      <td>Gifts</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>944</td>\n",
       "      <td>37</td>\n",
       "      <td>2012  bd</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>142</td>\n",
       "      <td>Cinema - Blu-Ray</td>\n",
       "      <td>Cinema</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11837</th>\n",
       "      <td>11837</td>\n",
       "      <td>66</td>\n",
       "      <td>zephyr stickers fairy tale alice   a...</td>\n",
       "      <td>3770</td>\n",
       "      <td>6829</td>\n",
       "      <td>12036</td>\n",
       "      <td>Gifts - Cards, stickers</td>\n",
       "      <td>Gifts</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20963</th>\n",
       "      <td>20963</td>\n",
       "      <td>57</td>\n",
       "      <td>freestyle oh  what   woman  mp3 cd  ...</td>\n",
       "      <td>1261</td>\n",
       "      <td>2294</td>\n",
       "      <td>4299</td>\n",
       "      <td>Music - MP3</td>\n",
       "      <td>Music</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>2231</td>\n",
       "      <td>58</td>\n",
       "      <td>creedence clearwater revival  creede...</td>\n",
       "      <td>805</td>\n",
       "      <td>1506</td>\n",
       "      <td>2715</td>\n",
       "      <td>Music - Vinyl</td>\n",
       "      <td>Music</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>4999</td>\n",
       "      <td>24</td>\n",
       "      <td>nba 2k15  xbox one  english version</td>\n",
       "      <td>2257</td>\n",
       "      <td>4116</td>\n",
       "      <td>7475</td>\n",
       "      <td>Games - XBOX ONE</td>\n",
       "      <td>Games</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10528</th>\n",
       "      <td>10528</td>\n",
       "      <td>40</td>\n",
       "      <td>grigori      dvds</td>\n",
       "      <td>1390</td>\n",
       "      <td>2562</td>\n",
       "      <td>4737</td>\n",
       "      <td>Cinema - DVD</td>\n",
       "      <td>Cinema</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11657</th>\n",
       "      <td>11657</td>\n",
       "      <td>41</td>\n",
       "      <td>star wars trilogy episodes        bd</td>\n",
       "      <td>3183</td>\n",
       "      <td>5829</td>\n",
       "      <td>10448</td>\n",
       "      <td>Cinema - Collector's</td>\n",
       "      <td>Cinema</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_id  category_id                                item_name  \\\n",
       "19287    19287           55           sat   best songs   pop chanson   \n",
       "5883      5883           19  prince   persia    forgotten sands  ...   \n",
       "16168    16168           64            board game munchkin  art 1938   \n",
       "944        944           37                                2012  bd    \n",
       "11837    11837           66  zephyr stickers fairy tale alice   a...   \n",
       "20963    20963           57  freestyle oh  what   woman  mp3 cd  ...   \n",
       "2231      2231           58  creedence clearwater revival  creede...   \n",
       "4999      4999           24     nba 2k15  xbox one  english version    \n",
       "10528    10528           40                       grigori      dvds    \n",
       "11657    11657           41    star wars trilogy episodes        bd    \n",
       "\n",
       "       item_name_first4  item_name_first6  item_name_first11  \\\n",
       "19287              2889              5162               9248   \n",
       "5883               2618              4703               8449   \n",
       "16168               521               909               1596   \n",
       "944                  63                80                142   \n",
       "11837              3770              6829              12036   \n",
       "20963              1261              2294               4299   \n",
       "2231                805              1506               2715   \n",
       "4999               2257              4116               7475   \n",
       "10528              1390              2562               4737   \n",
       "11657              3183              5829              10448   \n",
       "\n",
       "                         category_name group_name  group_id  \n",
       "19287   Music - CD of local production      Music        11  \n",
       "5883                       Games - PS3      Games         8  \n",
       "16168              Gifts - Board games      Gifts         9  \n",
       "944                   Cinema - Blu-Ray     Cinema         5  \n",
       "11837          Gifts - Cards, stickers      Gifts         9  \n",
       "20963                      Music - MP3      Music        11  \n",
       "2231                     Music - Vinyl      Music        11  \n",
       "4999                  Games - XBOX ONE      Games         8  \n",
       "10528                     Cinema - DVD     Cinema         5  \n",
       "11657             Cinema - Collector's     Cinema         5  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load items\n",
    "items = pd.read_csv('input/items.csv')\n",
    "print(items[48:49])\n",
    "#clean item_name\n",
    "items['item_name'] = items['item_name'].str.lower()\n",
    "items['item_name'] = items['item_name'].str.replace('.', '')\n",
    "for i in [r'[^\\w\\d\\s\\.]', r'\\bthe\\b', r'\\bin\\b', r'\\bis\\b',\n",
    "          r'\\bfor\\b', r'\\bof\\b', r'\\bon\\b', r'\\band\\b',  \n",
    "          r'\\bto\\b', r'\\bwith\\b' , r'\\byo\\b']:\n",
    "    items['item_name'] = items['item_name'].str.replace(i, ' ')\n",
    "items['item_name'] = items['item_name'].str.replace(r'\\b.\\b', ' ')\n",
    "\n",
    "#extract first n characters of name\n",
    "items['item_name_no_space'] = items['item_name'].str.replace(' ', '')\n",
    "items['item_name_first4'] = [x[:4] for x in items['item_name_no_space']]\n",
    "items['item_name_first6'] = [x[:6] for x in items['item_name_no_space']]\n",
    "items['item_name_first11'] = [x[:11] for x in items['item_name_no_space']]\n",
    "del items['item_name_no_space']\n",
    "                              \n",
    "#label encode these columns\n",
    "items.item_name_first4 = le.fit_transform(items.item_name_first4.values)\n",
    "items.item_name_first6 = le.fit_transform(items.item_name_first6.values)\n",
    "items.item_name_first11 = le.fit_transform(items.item_name_first11.values)\n",
    "\n",
    "#join category_name, group_name and group_id to items\n",
    "items = items.join(categories.set_index('category_id'), on='category_id')\n",
    "items.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicate rows exist in the item list. The following cell creates a dictionary that will allow us to reassign item id's where appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes = items[(items.duplicated(subset=['item_name','category_id'],keep=False))]\n",
    "dupes['in_test'] = dupes.item_id.isin(test.item_id.unique())\n",
    "dupes = dupes.groupby('item_name').agg({'item_id':['first','last'],'in_test':['first','last']})\n",
    "\n",
    "#if both item id's are in the test set do nothing\n",
    "dupes = dupes[(dupes[('in_test', 'first')]==False) | (dupes[('in_test', 'last')]==False)]\n",
    "#if only the first id is in the test set assign this id to both\n",
    "temp = dupes[dupes[('in_test', 'first')]==True]\n",
    "keep_first = dict(zip(temp[('item_id', 'last')], temp[('item_id',  'first')]))\n",
    "#if neither id or only the second id is in the test set, assign the second id to both\n",
    "temp = dupes[dupes[('in_test', 'first')]==False]\n",
    "keep_second = dict(zip(temp[('item_id', 'first')], temp[('item_id',  'last')]))\n",
    "item_map = {**keep_first, **keep_second}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2 Preparing Sales Information** <a id=\"22\"></a>\n",
    "\n",
    "We load sales.csv, remove the small proportion of rows without outlying values, use the dictionary we created above to reassign item id's where appropriate, then filter out sales for shops that don't exist in the test set and create features that need to be made before the data is grouped by month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loading sales data\n",
    "sales = pd.read_csv('input/sales_train.csv')\n",
    "sales = (sales\n",
    "    .query('0 < item_price < 50000 and 0 < item_cnt_day < 1001') #removing outliers\n",
    "    .replace({\n",
    "        'shop_id':{0:57, 1:58, 11:10}, #replacing obsolete shop id's\n",
    "        'item_id':item_map #fixing duplicate item id's  \n",
    "    })    \n",
    ")\n",
    "\n",
    "#removing shops which don't appear in the test set\n",
    "sales = sales[sales['shop_id'].isin(test.shop_id.unique())]\n",
    "\n",
    "sales['date'] = pd.to_datetime(sales.date,format='%d.%m.%Y')\n",
    "sales['weekday'] = sales.date.dt.dayofweek\n",
    "\n",
    "#first day the item was sold, day 0 is the first day of the training set period\n",
    "sales['first_sale_day'] = sales.date.dt.dayofyear \n",
    "sales['first_sale_day'] += 365 * (sales.date.dt.year-2013)\n",
    "sales['first_sale_day'] = sales.groupby('item_id')['first_sale_day'].transform('min').astype('int16')\n",
    "\n",
    "#revenue is needed to accurately calculate prices after grouping\n",
    "sales['revenue'] = sales['item_cnt_day']*sales['item_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the proportion of weekly sales that occurred on each weekday at each shop. Using this information we can assign a measure of weeks of sales power to each month. February always has 4 exactly weeks worth of days since there are no leap years in our time range and all other months have a value >4 since they have extra days of varying sales power. \n",
    "\n",
    "Month, year and first day of the month features are also created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>day_quality</th>\n",
       "      <th>first_day_of_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.300037</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.605952</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4.193211</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.333970</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4.472819</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4.287644</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4.492718</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4.313648</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4.300037</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4.386314</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4.412849</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.333970</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>14</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.566829</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     date_block_num  shop_id  month  year  day_quality  first_day_of_month\n",
       "18                0       28      1     0     4.300037                   1\n",
       "60                1       28      2     0     4.000000                  32\n",
       "102               2       28      3     0     4.605952                  60\n",
       "144               3       28      4     0     4.193211                  91\n",
       "186               4       28      5     0     4.333970                 121\n",
       "228               5       28      6     0     4.472819                 152\n",
       "270               6       28      7     0     4.287644                 182\n",
       "312               7       28      8     0     4.492718                 213\n",
       "354               8       28      9     0     4.313648                 244\n",
       "396               9       28     10     0     4.300037                 274\n",
       "438              10       28     11     0     4.386314                 305\n",
       "480              11       28     12     0     4.412849                 335\n",
       "522              12       28      1     1     4.333970                 366\n",
       "564              13       28      2     1     4.000000                 397\n",
       "606              14       28      3     1     4.566829                 425"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = sales.groupby(['shop_id','weekday']).agg({'item_cnt_day':'sum'}).reset_index()\n",
    "temp = pd.merge(temp, sales.groupby(['shop_id']).agg({'item_cnt_day':'sum'}).reset_index(), on='shop_id', how='left')\n",
    "temp.columns = ['shop_id','weekday', 'shop_day_sales', 'shop_total_sales']\n",
    "temp['day_quality'] = temp['shop_day_sales']/temp['shop_total_sales']\n",
    "temp = temp[['shop_id','weekday','day_quality']]\n",
    "\n",
    "dates = pd.DataFrame(data={'date':pd.date_range(start='2013-01-01',end='2015-11-30')})\n",
    "dates['weekday'] = dates.date.dt.dayofweek\n",
    "dates['month'] = dates.date.dt.month\n",
    "dates['year'] = dates.date.dt.year - 2013\n",
    "dates['date_block_num'] = dates['year']*12 + dates['month'] - 1\n",
    "dates['first_day_of_month'] = dates.date.dt.dayofyear\n",
    "dates['first_day_of_month'] += 365 * dates['year']\n",
    "dates = dates.join(temp.set_index('weekday'), on='weekday')\n",
    "dates = dates.groupby(['date_block_num','shop_id','month','year']).agg({'day_quality':'sum','first_day_of_month':'min'}).reset_index()\n",
    "\n",
    "dates.query('shop_id == 28').head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now group the sales data by month, shop_id a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_cnt</th>\n",
       "      <th>revenue</th>\n",
       "      <th>first_sale_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>423024</th>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>3656</td>\n",
       "      <td>3.0</td>\n",
       "      <td>897.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017489</th>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>17956</td>\n",
       "      <td>1.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546581</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>9798</td>\n",
       "      <td>1.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179143</th>\n",
       "      <td>29</td>\n",
       "      <td>19</td>\n",
       "      <td>2946</td>\n",
       "      <td>1.0</td>\n",
       "      <td>449.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356848</th>\n",
       "      <td>7</td>\n",
       "      <td>47</td>\n",
       "      <td>6601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1149.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date_block_num  shop_id  item_id  item_cnt  revenue  first_sale_day\n",
       "423024                9       25     3656       3.0    897.0               5\n",
       "1017489              24       25    17956       1.0    169.0             330\n",
       "546581               12        5     9798       1.0    199.0             263\n",
       "1179143              29       19     2946       1.0    449.0               1\n",
       "356848                7       47     6601       1.0   1149.0               2"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales = (sales\n",
    "     .groupby(['date_block_num', 'shop_id', 'item_id'])\n",
    "     .agg({\n",
    "         'item_cnt_day':'sum', \n",
    "         'revenue':'sum',\n",
    "         'first_sale_day':'first'\n",
    "     })\n",
    "     .reset_index()\n",
    "     .rename(columns={'item_cnt_day':'item_cnt'})\n",
    ")\n",
    "sales.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3 Constructing Training Dataframe** <a id=\"23\"></a>\n",
    "\n",
    "The test set consists of the cartesian product of 42 shops and 5100 items. To make a training set which approximates the test set we create a training dataframe consisting of the cartesian product (active items) x (active shops) for each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>317</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>438</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>471</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  item_id  date_block_num\n",
       "0        2       27               0\n",
       "1        2       33               0\n",
       "2        2      317               0\n",
       "3        2      438               0\n",
       "4        2      471               0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = [] \n",
    "for block_num in sales['date_block_num'].unique():\n",
    "    cur_shops = sales.loc[sales['date_block_num'] == block_num, 'shop_id'].unique()\n",
    "    cur_items = sales.loc[sales['date_block_num'] == block_num, 'item_id'].unique()\n",
    "    df.append(np.array(list(product(*[cur_shops, cur_items, [block_num]]))))\n",
    "\n",
    "df = pd.DataFrame(np.vstack(df), columns=['shop_id', 'item_id', 'date_block_num'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the appropriate date_block_num value to the test set\n",
    "test['date_block_num'] = 34\n",
    "del test['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append test set to training dataframe\n",
    "df = pd.concat([df,test]).fillna(0)\n",
    "df = df.reset_index()\n",
    "del df['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join sales and item inforamtion to the training dataframe\n",
    "df = pd.merge(df, sales, on=['shop_id', 'item_id', 'date_block_num'], how='left').fillna(0)\n",
    "df = pd.merge(df, dates, on=['date_block_num','shop_id'], how='left')\n",
    "df = pd.merge(df, items.drop(columns=['item_name','group_name','category_name']), on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4 Adding Shop Information** <a id=\"24\"></a>\n",
    "\n",
    "We cluster the shops using K-means clustering, using the proportion of their sales they make in each category as features.\n",
    "\n",
    "k=7 was selected because:\n",
    "* k=7 resulted in the highest average silhouette score aside from a choice of k=2. \n",
    "* k=2 would not provide a useful clustering because it creates a feature with value (shop_id==55)\\*1. \n",
    "* k=7 is also in an appropriate area when using the elbow method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading shops.csv\n",
    "shops = pd.read_csv('input/shops.csv')\n",
    "\n",
    "#clustering shops\n",
    "shops_cats = pd.DataFrame(\n",
    "    np.array(list(product(*[df['shop_id'].unique(), df['category_id'].unique()]))),\n",
    "    columns =['shop_id', 'category_id']\n",
    ")\n",
    "temp = df.groupby(['category_id', 'shop_id']).agg({'item_cnt':'sum'}).reset_index()\n",
    "temp2 = temp.groupby('shop_id').agg({'item_cnt':'sum'}).rename(columns={'item_cnt':'shop_total'})\n",
    "temp = temp.join(temp2, on='shop_id')\n",
    "temp['category_proportion'] = temp['item_cnt']/temp['shop_total']\n",
    "temp = temp[['shop_id', 'category_id', 'category_proportion']]\n",
    "shops_cats = pd.merge(shops_cats, temp, on=['shop_id','category_id'], how='left')\n",
    "shops_cats = shops_cats.fillna(0)\n",
    "\n",
    "shops_cats = shops_cats.pivot(index='shop_id', columns=['category_id'])\n",
    "kmeans = KMeans(n_clusters=7, random_state=0).fit(shops_cats)\n",
    "shops_cats['shop_cluster'] = kmeans.labels_.astype('int8')\n",
    "\n",
    "#adding these clusters to the shops dataframe\n",
    "shops = shops.join(shops_cats['shop_cluster'], on='shop_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clean the shop names column then use the opening word to create the shop_city feature. We then create the shop_type feature based on terms that occur in the name of the shop. Both these features are then label encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_name</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>shop_cluster</th>\n",
       "      <th>shop_type</th>\n",
       "      <th>shop_city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adygea tc  mega</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>balashikha tc  oktyabr kinomir</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>volga tc  volga mall</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vologda sec  marmelad</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>voronezh  plekhanovskaya  13</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          shop_name  shop_id  shop_cluster  shop_type  \\\n",
       "2                  adygea tc  mega         2           0.0          0   \n",
       "3   balashikha tc  oktyabr kinomir         3           3.0          3   \n",
       "4             volga tc  volga mall         4           3.0          0   \n",
       "5            vologda sec  marmelad         5           3.0          2   \n",
       "6     voronezh  plekhanovskaya  13         6           3.0          2   \n",
       "\n",
       "   shop_city  \n",
       "2          0  \n",
       "3          1  \n",
       "4         22  \n",
       "5         23  \n",
       "6         24  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing unused shop ids\n",
    "shops.dropna(inplace=True)\n",
    "\n",
    "#cleaning the name column\n",
    "shops['shop_name'] = shops['shop_name'].str.lower()\n",
    "shops['shop_name'] = shops['shop_name'].str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "\n",
    "#creating a column for the type of shop\n",
    "shops['shop_type'] = 'regular'\n",
    "\n",
    "#there is some overlap in tc and mall, mall is given precedence\n",
    "shops.loc[shops['shop_name'].str.contains(r'tc'), 'shop_type'] = 'tc'\n",
    "shops.loc[shops['shop_name'].str.contains(r'mall|center|mega'), 'shop_type'] = 'mall'\n",
    "shops.loc[shops['shop_id'].isin([9,20]), 'shop_type'] = 'special'\n",
    "shops.loc[shops['shop_id'].isin([12,55]), 'shop_type'] = 'online'\n",
    "\n",
    "#the first word of shop name is largely sufficient as a city feature\n",
    "shops['shop_city'] = shops['shop_name'].str.split().str[0]\n",
    "shops.loc[shops['shop_id'].isin([12,55]), 'shop_city'] = 'online'\n",
    "shops.shop_city = le.fit_transform(shops.shop_city.values)\n",
    "shops.shop_type = le.fit_transform(shops.shop_type.values)\n",
    "shops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>item_cnt</th>\n",
       "      <th>revenue</th>\n",
       "      <th>first_sale_day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>day_quality</th>\n",
       "      <th>first_day_of_month</th>\n",
       "      <th>category_id</th>\n",
       "      <th>item_name_first4</th>\n",
       "      <th>item_name_first6</th>\n",
       "      <th>item_name_first11</th>\n",
       "      <th>group_id</th>\n",
       "      <th>shop_cluster</th>\n",
       "      <th>shop_type</th>\n",
       "      <th>shop_city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2499.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.381749</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.381749</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>415</td>\n",
       "      <td>720</td>\n",
       "      <td>1203</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>317</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.381749</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>438</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.381749</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "      <td>57</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>471</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>798.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.381749</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>37</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  item_id  date_block_num  item_cnt  revenue  first_sale_day  month  \\\n",
       "0        2       27               0       1.0   2499.0             2.0      1   \n",
       "1        2       33               0       1.0    499.0             2.0      1   \n",
       "2        2      317               0       1.0    299.0             4.0      1   \n",
       "3        2      438               0       1.0    299.0            19.0      1   \n",
       "4        2      471               0       2.0    798.0             3.0      1   \n",
       "\n",
       "   year  day_quality  first_day_of_month  category_id  item_name_first4  \\\n",
       "0     0     4.381749                   1           19                 2   \n",
       "1     0     4.381749                   1           37               415   \n",
       "2     0     4.381749                   1           45                31   \n",
       "3     0     4.381749                   1           45                31   \n",
       "4     0     4.381749                   1           49                30   \n",
       "\n",
       "   item_name_first6  item_name_first11  group_id  shop_cluster  shop_type  \\\n",
       "0                 2                  2         8           0.0          0   \n",
       "1               720               1203         5           0.0          0   \n",
       "2                38                 52         4           0.0          0   \n",
       "3                38                 57         4           0.0          0   \n",
       "4                37                 51         4           0.0          0   \n",
       "\n",
       "   shop_city  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add shop information to the training dataframe\n",
    "df = pd.merge(df, shops.drop(columns='shop_name'), on='shop_id', how='left')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5 Ages & Aggregating Sales/Price information** <a id=\"25\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a feature showing how many days have passed between the first time an item was sold and the beginning of the current month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['first_sale_day'] = df.groupby('item_id')['first_sale_day'].transform('max').astype('int16')\n",
    "df.loc[df['first_sale_day']==0, 'first_sale_day'] = 1035\n",
    "df['prev_days_on_sale'] = [max(idx) for idx in zip(df['first_day_of_month']-df['first_sale_day'],[0]*len(df))]\n",
    "del df['first_day_of_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>item_cnt</th>\n",
       "      <th>revenue</th>\n",
       "      <th>first_sale_day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>day_quality</th>\n",
       "      <th>category_id</th>\n",
       "      <th>item_name_first4</th>\n",
       "      <th>item_name_first6</th>\n",
       "      <th>item_name_first11</th>\n",
       "      <th>group_id</th>\n",
       "      <th>shop_cluster</th>\n",
       "      <th>shop_type</th>\n",
       "      <th>shop_city</th>\n",
       "      <th>prev_days_on_sale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2499.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.381749</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.381749</td>\n",
       "      <td>37</td>\n",
       "      <td>415</td>\n",
       "      <td>720</td>\n",
       "      <td>1203</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>317</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.381749</td>\n",
       "      <td>45</td>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>438</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.381749</td>\n",
       "      <td>45</td>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "      <td>57</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>471</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>798.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.381749</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>37</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  item_id  date_block_num  item_cnt  revenue  first_sale_day  month  \\\n",
       "0        2       27               0       1.0   2499.0               2      1   \n",
       "1        2       33               0       1.0    499.0               2      1   \n",
       "2        2      317               0       1.0    299.0               4      1   \n",
       "3        2      438               0       1.0    299.0              19      1   \n",
       "4        2      471               0       2.0    798.0               3      1   \n",
       "\n",
       "   year  day_quality  category_id  item_name_first4  item_name_first6  \\\n",
       "0     0     4.381749           19                 2                 2   \n",
       "1     0     4.381749           37               415               720   \n",
       "2     0     4.381749           45                31                38   \n",
       "3     0     4.381749           45                31                38   \n",
       "4     0     4.381749           49                30                37   \n",
       "\n",
       "   item_name_first11  group_id  shop_cluster  shop_type  shop_city  \\\n",
       "0                  2         8           0.0          0          0   \n",
       "1               1203         5           0.0          0          0   \n",
       "2                 52         4           0.0          0          0   \n",
       "3                 57         4           0.0          0          0   \n",
       "4                 51         4           0.0          0          0   \n",
       "\n",
       "   prev_days_on_sale  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#freeing RAM, removing unneeded columns and encoding object columns\n",
    "del sales, categories, shops, shops_cats, temp, temp2, test, dupes, item_map, \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to clip the target value before aggregating so that mean values are not distorted due to outliers. We retain the unclipped value for use in features that do not aggregate the sales data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['item_cnt_unclipped'] = df['item_cnt']\n",
    "df['item_cnt'] = df['item_cnt'].clip(0, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No columns with float dtype require more than float32 precision and no int dtype columns require values outside the int16 range. The following function will compress the data types of these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast(df):\n",
    "    #reduce size of the dataframe\n",
    "    float_cols = [c for c in df if df[c].dtype in [\"float64\"]]\n",
    "    int_cols = [c for c in df if df[c].dtype in ['int64']]\n",
    "    df[float_cols] = df[float_cols].astype('float32')\n",
    "    df[int_cols] = df[int_cols].astype('int16')\n",
    "    return df\n",
    "df = downcast(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These features show how many months have passed since the first appearance of the item/name/category/group/shop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['item_age'] = (df['date_block_num'] - df.groupby('item_id')['date_block_num'].transform('min')).astype('int8')\n",
    "df['item_name_first4_age'] = (df['date_block_num'] - df.groupby('item_name_first4')['date_block_num'].transform('min')).astype('int8')\n",
    "df['item_name_first6_age'] = (df['date_block_num'] - df.groupby('item_name_first6')['date_block_num'].transform('min')).astype('int8')\n",
    "df['item_name_first11_age'] = (df['date_block_num'] - df.groupby('item_name_first11')['date_block_num'].transform('min')).astype('int8')\n",
    "df['category_age'] = (df['date_block_num'] - df.groupby('category_id')['date_block_num'].transform('min')).astype('int8')\n",
    "df['group_age'] = (df['date_block_num'] - df.groupby('group_id')['date_block_num'].transform('min')).astype('int8')\n",
    "df['shop_age'] = (df['date_block_num'] - df.groupby('shop_id')['date_block_num'].transform('min')).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indicates whether shops have previously sold the item\n",
    "temp = df.query('item_cnt > 0').groupby(['item_id','shop_id']).agg({'date_block_num':'min'}).reset_index()\n",
    "temp.columns = ['item_id', 'shop_id', 'item_shop_first_sale']\n",
    "df = pd.merge(df, temp, on=['item_id','shop_id'], how='left')\n",
    "df['item_shop_first_sale'] = df['item_shop_first_sale'].fillna(50)\n",
    "#item age that stays at 0 if a shop hasn't sold the item\n",
    "df['item_age_if_shop_sale'] = (df['date_block_num'] > df['item_shop_first_sale']) * df['item_age']\n",
    "#the length of time an item has been for sale without being sold at individual shops\n",
    "df['item_age_without_shop_sale'] = (df['date_block_num'] <= df['item_shop_first_sale']) * df['item_age']\n",
    "del df['item_shop_first_sale']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable, 'item_cnt', is the monthly sale count of individual items at individual shops. We now create features showing average monthly sales based on various groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_cnt_col(df, merging_cols, new_col,aggregation):\n",
    "    temp = df.groupby(merging_cols).agg(aggregation).reset_index()\n",
    "    temp.columns = merging_cols + [new_col]\n",
    "    df = pd.merge(df, temp, on=merging_cols, how='left')\n",
    "    return df\n",
    "\n",
    "#individual items across all shops\n",
    "df = agg_cnt_col(df, ['date_block_num','item_id'],'item_cnt_all_shops',{'item_cnt':'mean'})\n",
    "df = agg_cnt_col(df, ['date_block_num','category_id','shop_id'],'item_cnt_all_shops_median',{'item_cnt':'median'}) \n",
    "#all items in category at individual shops\n",
    "df = agg_cnt_col(df, ['date_block_num','category_id','shop_id'],'category_cnt',{'item_cnt':'mean'})\n",
    "df = agg_cnt_col(df, ['date_block_num','category_id','shop_id'],'category_cnt_median',{'item_cnt':'median'}) \n",
    "#all items in category across all shops\n",
    "df = agg_cnt_col(df, ['date_block_num','category_id'],'category_cnt_all_shops',{'item_cnt':'mean'})\n",
    "df = agg_cnt_col(df, ['date_block_num','category_id'],'category_cnt_all_shops_median',{'item_cnt':'median'})\n",
    "#all items in group\n",
    "df = agg_cnt_col(df, ['date_block_num','group_id','shop_id'],'group_cnt',{'item_cnt':'mean'})\n",
    "#all items in group across all shops\n",
    "df = agg_cnt_col(df, ['date_block_num','group_id'],'group_cnt_all_shops',{'item_cnt':'mean'})\n",
    "#all items at individual shops\n",
    "df = agg_cnt_col(df, ['date_block_num','shop_id'],'shop_cnt',{'item_cnt':'mean'})\n",
    "#all items at all shops within the city\n",
    "df = agg_cnt_col(df, ['date_block_num','shop_city'],'city_cnt',{'item_cnt':'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create features showing the mean first month sales for items in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_item_sales(df, merging_cols, new_col):\n",
    "    temp = (\n",
    "        df\n",
    "        .query('item_age==0')\n",
    "        .groupby(merging_cols)['item_cnt']\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "        .rename(columns={'item_cnt': new_col})\n",
    "    )\n",
    "    df = pd.merge(df, temp, on=merging_cols, how='left')\n",
    "    return df\n",
    "\n",
    "#mean units sold of new item in category at individual shop\n",
    "df = new_item_sales(df, ['date_block_num','category_id','shop_id'], 'new_items_in_cat')\n",
    "#mean units sold of new item in category across all shops\n",
    "df = new_item_sales(df, ['date_block_num','category_id'], 'new_items_in_cat_all_shops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_price_col(df, merging_cols, new_col):\n",
    "    temp = df.groupby(merging_cols).agg({'revenue':'sum','item_cnt_unclipped':'sum'}).reset_index()\n",
    "    temp[new_col] = temp['revenue']/temp['item_cnt_unclipped']\n",
    "    temp = temp[merging_cols + [new_col]]\n",
    "    df = pd.merge(df, temp, on=merging_cols, how='left')\n",
    "    return df\n",
    "\n",
    "#average item price\n",
    "df = agg_price_col(df,['date_block_num','item_id'],'item_price')\n",
    "#average price of items in category\n",
    "df = agg_price_col(df,['date_block_num','category_id'],'category_price')\n",
    "#average price of all items\n",
    "df = agg_price_col(df,['date_block_num'],'block_price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = downcast(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.6 Lagging Values & Features that use Prior Information** <a id=\"26\"></a>\n",
    "\n",
    "The following function will be used to create lag features of varying lag periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_feature(df, lag, col, merge_cols):        \n",
    "    temp = df[merge_cols + [col]]\n",
    "    temp = temp.groupby(merge_cols).agg({f'{col}':'first'}).reset_index()\n",
    "    temp.columns = merge_cols + [f'{col}_lag{lag}']\n",
    "    temp['date_block_num'] += lag\n",
    "    df = pd.merge(df, temp, on=merge_cols, how='left')\n",
    "    df[f'{col}_lag{lag}'] = df[f'{col}_lag{lag}'].fillna(0).astype('float32')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These features each have 3 lagged columns returned:\n",
    "* lag1 shows the value of the prior month\n",
    "* lag2 shows the value two months prior\n",
    "* lag1to12 is the sum of values across the previous 12 months\n",
    "\n",
    "Original columns will be deleted when they are no longer needed to avoid data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag12_cols = {\n",
    "    'item_cnt':['date_block_num', 'shop_id', 'item_id'],\n",
    "    'item_cnt_all_shops':['date_block_num', 'item_id'],\n",
    "    'category_cnt':['date_block_num', 'shop_id', 'category_id'],\n",
    "    'category_cnt_all_shops':['date_block_num', 'category_id'],\n",
    "    'group_cnt':['date_block_num', 'shop_id', 'group_id'],\n",
    "    'group_cnt_all_shops':['date_block_num', 'group_id'],\n",
    "    'shop_cnt':['date_block_num', 'shop_id'],\n",
    "    'city_cnt':['date_block_num', 'shop_city'],\n",
    "    'new_items_in_cat':['date_block_num', 'shop_id', 'category_id'],\n",
    "    'new_items_in_cat_all_shops':['date_block_num', 'category_id']\n",
    "}\n",
    "for col,merge_cols in lag12_cols.items():\n",
    "    df[f'{col}_lag1to12'] = 0\n",
    "    for i in range(1,13):\n",
    "        df = lag_feature(df, i, col, merge_cols)\n",
    "        df[f'{col}_lag1to12'] += df[f'{col}_lag{i}']\n",
    "        if i > 2:\n",
    "            del df[f'{col}_lag{i}']\n",
    "    if col == 'item_cnt':\n",
    "        del df[f'{col}_lag1']\n",
    "        del df[f'{col}_lag2']        \n",
    "    else:\n",
    "        del df[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take lag1 and lag2 values for these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag2_cols = {\n",
    "    'item_cnt_unclipped':['date_block_num', 'shop_id', 'item_id'],\n",
    "    'item_cnt_all_shops_median':['date_block_num', 'item_id'],\n",
    "    'category_cnt_median':['date_block_num', 'shop_id', 'category_id'],\n",
    "    'category_cnt_all_shops_median':['date_block_num', 'category_id']\n",
    "}\n",
    "for col in lag2_cols:\n",
    "    df = lag_feature(df, 1, col, merge_cols)\n",
    "    df = lag_feature(df, 2, col, merge_cols)\n",
    "    if col!='item_cnt_unclipped':\n",
    "        del df[col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These features show the ratio between lag1 and lag1to12 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['item_cnt_diff'] = df['item_cnt_unclipped_lag1']/df['item_cnt_lag1to12']\n",
    "df['item_cnt_all_shops_diff'] = df['item_cnt_all_shops_lag1']/df['item_cnt_all_shops_lag1to12']\n",
    "df['category_cnt_diff'] = df['category_cnt_lag1']/df['category_cnt_lag1to12']\n",
    "df['category_cnt_all_shops_diff'] = df['category_cnt_all_shops_lag1']/df['category_cnt_all_shops_lag1to12']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create lag1 values for category and block prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = lag_feature(df, 1, 'category_price',['date_block_num', 'category_id'])\n",
    "df = lag_feature(df, 1, 'block_price',['date_block_num'])\n",
    "del df['category_price'], df['block_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fill the missing values in the below columns with 0 because we know this is the correct value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['item_age']>0) & (df['item_cnt_lag1to12'].isna()), 'item_cnt_lag1to12'] = 0\n",
    "df.loc[(df['category_age']>0) & (df['category_cnt_lag1to12'].isna()), 'category_cnt_lag1to12'] = 0\n",
    "df.loc[(df['group_age']>0) & (df['group_cnt_lag1to12'].isna()), 'group_cnt_lag1to12'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, lag1to12 values are the sum of values over the previous 12 months. Differing ages in the dataset mean that some lag1to12 values are calculated over the previous 12 months, but others have had less time to accrue. \n",
    "\n",
    "We divide lag1to12 values by the minimum between 12 and previous periods in the dataset. This turns lag1to12 into a monthly average that can be more accurately compared between datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['item_cnt_lag1to12'] /= [min(idx) for idx in zip(df['item_age'],df['shop_age'],[12]*len(df))]\n",
    "df['item_cnt_all_shops_lag1to12'] /= [min(idx) for idx in zip(df['item_age'],[12]*len(df))]\n",
    "df['category_cnt_lag1to12'] /= [min(idx) for idx in zip(df['category_age'],df['shop_age'],[12]*len(df))]\n",
    "df['category_cnt_all_shops_lag1to12'] /= [min(idx) for idx in zip(df['category_age'],[12]*len(df))]\n",
    "df['group_cnt_lag1to12'] /= [min(idx) for idx in zip(df['group_age'],df['shop_age'],[12]*len(df))]\n",
    "df['group_cnt_all_shops_lag1to12'] /= [min(idx) for idx in zip(df['group_age'],[12]*len(df))]\n",
    "df['city_cnt_lag1to12'] /= [min(idx) for idx in zip(df['date_block_num'],[12]*len(df))]\n",
    "df['shop_cnt_lag1to12'] /= [min(idx) for idx in zip(df['shop_age'],[12]*len(df))]\n",
    "df['new_items_in_cat_lag1to12'] /= [min(idx) for idx in zip(df['category_age'],df['shop_age'],[12]*len(df))]\n",
    "df['new_items_in_cat_all_shops_lag1to12'] /= [min(idx) for idx in zip(df['category_age'],[12]*len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = downcast(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These features use past information across more than one period of the dataset. They are not suitable to be lagged in the normal manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def past_information(df, merging_cols, new_col, aggregation):\n",
    "    temp = []\n",
    "    for i in range(1,35):\n",
    "        block = df.query(f'date_block_num < {i}').groupby(merging_cols).agg(aggregation).reset_index()\n",
    "        block.columns = merging_cols + [new_col]\n",
    "        block['date_block_num'] = i\n",
    "        block = block[block[new_col]>0]\n",
    "        temp.append(block)\n",
    "    temp = pd.concat(temp)\n",
    "    df = pd.merge(df, temp, on=['date_block_num']+merging_cols, how='left')\n",
    "    return df\n",
    "\n",
    "#average item price in latest block item was sold\n",
    "df = past_information(df, ['item_id'],'last_item_price',{'item_price':'last'})\n",
    "#total units of item sold at individual shop\n",
    "df = past_information(df, ['shop_id','item_id'],'item_cnt_sum_alltime',{'item_cnt':'sum'})\n",
    "#total units of item sold at all shops\n",
    "df = past_information(df, ['item_id'],'item_cnt_sum_alltime_allshops',{'item_cnt':'sum'})\n",
    "\n",
    "#these columns are no longer needed, and would cause data leakage if retained\n",
    "del df['revenue'], df['item_cnt_unclipped'], df['item_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature showing item prices relative to the block price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['relative_price_item_block_lag1'] = df['last_item_price']/df['block_price_lag1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These features show per day sales values since an item was first sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['item_cnt_per_day_alltime'] = (df['item_cnt_sum_alltime']/df['prev_days_on_sale']).fillna(0)\n",
    "df['item_cnt_per_day_alltime_allshops'] = (df['item_cnt_sum_alltime_allshops']/df['prev_days_on_sale']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "df = downcast(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These features show the mean sales of items with names that have the same first n characters, in the same category and at the same item age. The hope is that this feature can catch past performance of similar items such as earlier titles in a series, particularly in their debut month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_name_cat_age(df,n,all_shops):\n",
    "    temp_cols = [f'same_name{n}catage_cnt','date_block_num', f'item_name_first{n}','item_age','category_id']\n",
    "    if all_shops:\n",
    "        temp_cols[0] += '_all_shops'\n",
    "    else:\n",
    "        temp_cols += ['shop_id']\n",
    "    temp = []\n",
    "    for i in range(1,35):\n",
    "        block = (\n",
    "            df\n",
    "            .query(f'date_block_num < {i}')\n",
    "            .groupby(temp_cols[2:])\n",
    "            .agg({'item_cnt':'mean'})\n",
    "            .reset_index()\n",
    "            .rename(columns={'item_cnt':temp_cols[0]})\n",
    "        )\n",
    "        block = block[block[temp_cols[0]]>0]\n",
    "        block['date_block_num'] = i\n",
    "        temp.append(block)\n",
    "    temp = pd.concat(temp)\n",
    "    df = pd.merge(df, temp, on=temp_cols[1:], how='left')\n",
    "    return df\n",
    "\n",
    "for n in [4,6,11]:\n",
    "    for all_shops in [True,False]:\n",
    "        df = matching_name_cat_age(df,n,all_shops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign appropriate datatypes\n",
    "df = downcast(df)\n",
    "int8_cols = [\n",
    "    'item_cnt','month','group_id','shop_type',\n",
    "    'shop_city','shop_id','date_block_num','category_id',\n",
    "    'item_age',\n",
    "]\n",
    "int16_cols = [\n",
    "    'item_id','item_name_first4',\n",
    "    'item_name_first6','item_name_first11'\n",
    "]\n",
    "for col in int8_cols:\n",
    "    df[col] = df[col].astype('int8')\n",
    "for col in int16_cols:\n",
    "    df[col] = df[col].astype('int16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These features show sales data for items with item_id 1 above and 1 below the item in question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearby_item_data(df,col):\n",
    "    if col in ['item_cnt_unclipped_lag1','item_cnt_lag1to12']:\n",
    "        cols = ['date_block_num', 'shop_id', 'item_id']\n",
    "        temp = df[cols + [col]] \n",
    "    else:\n",
    "        cols = ['date_block_num', 'item_id']\n",
    "        temp = df.groupby(cols).agg({col:'first'}).reset_index()[cols + [col]]   \n",
    "    \n",
    "    temp.columns = cols + [f'below_{col}']\n",
    "    temp['item_id'] += 1\n",
    "    df = pd.merge(df, temp, on=cols, how='left')\n",
    "    \n",
    "    temp.columns = cols + [f'above_{col}']\n",
    "    temp['item_id'] -= 2\n",
    "    df = pd.merge(df, temp, on=cols, how='left')\n",
    "    \n",
    "    return df\n",
    "\n",
    "item_cols = ['item_cnt_unclipped_lag1','item_cnt_lag1to12',\n",
    "             'item_cnt_all_shops_lag1','item_cnt_all_shops_lag1to12']\n",
    "for col in item_cols:\n",
    "    df = nearby_item_data(df,col)\n",
    "    \n",
    "del temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.7 Encoding Name Information** <a id=\"27\"></a>\n",
    "\n",
    "We add boolean features indicating whether an item's name contains any words which frequently appear in the item set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Counter()\n",
    "items['item_name'].str.split().apply(results.update)\n",
    "\n",
    "words = []\n",
    "cnts = []\n",
    "for key, value in results.items():\n",
    "    words.append(key)\n",
    "    cnts.append(value)\n",
    "    \n",
    "counts = pd.DataFrame({'word':words,'count':cnts})\n",
    "common_words = counts.query('count>200').word.to_list()\n",
    "for word in common_words:\n",
    "    items[f'{word}_in_name'] = items['item_name'].str.contains(word).astype('int8')\n",
    "drop_cols = [\n",
    "    'item_id','category_id','item_name','item_name_first4',\n",
    "    'item_name_first6','item_name_first11',\n",
    "    'category_name','group_name','group_id'\n",
    "]\n",
    "items = items.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join these word vectors to the training dataframe\n",
    "df = df.join(items, on='item_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given it's high cardinality, we use binary encoding to create a better representation of item_name_first11. The other name features are now deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_encode(df, letters, cols):\n",
    "    encoder = ce.BinaryEncoder(cols=[f'item_name_first{letters}'], return_df=True)\n",
    "    temp = encoder.fit_transform(df[f'item_name_first{letters}'])\n",
    "    df = pd.concat([df,temp], axis=1)\n",
    "    del df[f'item_name_first{letters}_0']\n",
    "    name_cols = [f'item_name_first{letters}_{x}' for x in range(1,cols)]\n",
    "    df[name_cols] = df[name_cols].astype('int8')\n",
    "    return df\n",
    "\n",
    "df = binary_encode(df, 11, 15)\n",
    "    \n",
    "del df['item_name_first4'], df['item_name_first6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataframe for later use\n",
    "df.to_pickle('df_complete.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset the kernel to clear memory.\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modelling<a id=\"30\"></a>\n",
    "[1. Introduction](#10)  \n",
    "[2. Preparing Dataset](#20)  \n",
    "&nbsp;&nbsp;[2.1 Preparing Item/Category Information](#21)  \n",
    "&nbsp;&nbsp;[2.2 Preparing Sales Information](#22)  \n",
    "&nbsp;&nbsp;[2.3 Constructing Training Dataframe](#23)  \n",
    "&nbsp;&nbsp;[2.4 Adding Shop Information](#24)  \n",
    "&nbsp;&nbsp;[2.5 Ages & Aggregating Sales/Price information](#25)  \n",
    "&nbsp;&nbsp;[2.6 Lagging Values & Features that use Prior Information](#26)  \n",
    "&nbsp;&nbsp;[2.7 Encoding Name Information](#27)  \n",
    "[3. Modelling](#30)  \n",
    "&nbsp;&nbsp;[3.1 Training Model](#31)  \n",
    "&nbsp;&nbsp;[3.2 Submitting](#32)  \n",
    "[4. Analysing Model Output](#40)  \n",
    "&nbsp;&nbsp;[4.1 Plots](#41)  \n",
    "&nbsp;&nbsp;[4.2 Table Views](#42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shap\n",
      "  Downloading shap-0.39.0.tar.gz (356 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\sogang\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from shap) (1.20.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\sogang\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from shap) (1.6.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sogang\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from shap) (0.24.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\sogang\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from shap) (1.2.4)\n",
      "Requirement already satisfied: tqdm>4.25.0 in c:\\users\\sogang\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from shap) (4.60.0)\n",
      "Collecting slicer==0.0.7\n",
      "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Collecting numba\n",
      "  Downloading numba-0.53.1-cp39-cp39-win_amd64.whl (2.3 MB)\n",
      "Collecting cloudpickle\n",
      "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sogang\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from numba->shap) (49.2.1)\n",
      "Collecting llvmlite<0.37,>=0.36.0rc1\n",
      "  Downloading llvmlite-0.36.0-cp39-cp39-win_amd64.whl (16.0 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\sogang\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->shap) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\sogang\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->shap) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sogang\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sogang\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->shap) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\sogang\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->shap) (1.0.1)\n",
      "Building wheels for collected packages: shap\n",
      "  Building wheel for shap (setup.py): started\n",
      "  Building wheel for shap (setup.py): finished with status 'done'\n",
      "  Created wheel for shap: filename=shap-0.39.0-cp39-cp39-win_amd64.whl size=413381 sha256=90fb121e5ecc0df4a4e171768ba4e0d6a1b71dc572e5d3998ac12d3eeba335af\n",
      "  Stored in directory: c:\\users\\sogang\\appdata\\local\\pip\\cache\\wheels\\bb\\91\\16\\f6a057925f93af7e4281f6afce3495b595b473342766eb451c\n",
      "Successfully built shap\n",
      "Installing collected packages: llvmlite, slicer, numba, cloudpickle, shap\n",
      "Successfully installed cloudpickle-1.6.0 llvmlite-0.36.0 numba-0.53.1 shap-0.39.0 slicer-0.0.7\n"
     ]
    }
   ],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading plotly-4.14.3-py2.py3-none-any.whl (13.2 MB)\n",
      "Requirement already satisfied: six in c:\\users\\sogang\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from plotly) (1.15.0)\n",
      "Collecting retrying>=1.3.3\n",
      "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
      "Building wheels for collected packages: retrying\n",
      "  Building wheel for retrying (setup.py): started\n",
      "  Building wheel for retrying (setup.py): finished with status 'done'\n",
      "  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11429 sha256=be273a21bcab87dbf8cdc2ce8f6e4e60b076a216d3938080142c863a5777485c\n",
      "  Stored in directory: c:\\users\\sogang\\appdata\\local\\pip\\cache\\wheels\\ce\\18\\7f\\e9527e3e66db1456194ac7f61eb3211068c409edceecff2d31\n",
      "Successfully built retrying\n",
      "Installing collected packages: retrying, plotly\n",
      "Successfully installed plotly-4.14.3 retrying-1.3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "pd.set_option('display.max_rows', 160)\n",
    "pd.set_option('display.max_columns', 160)\n",
    "pd.set_option('display.max_colwidth', 30)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the training, validation, and test sets. The first 2 months are not used for training as many feature values are likely to be misrepresentative in this period. \n",
    "\n",
    "The month of data directly before the test period is used as our validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the saved training dataframe\n",
    "df = pd.read_pickle('C:/Users/SOGANG/Downloads/df_complete.pkl')\n",
    "\n",
    "X_train = df[~df.date_block_num.isin([0,1,33,34])]\n",
    "y_train = X_train['item_cnt']\n",
    "del X_train['item_cnt']\n",
    "\n",
    "X_val = df[df['date_block_num']==33]\n",
    "y_val = X_val['item_cnt']\n",
    "del X_val['item_cnt']\n",
    "\n",
    "X_test = df[df['date_block_num']==34].drop(columns='item_cnt')\n",
    "X_test = X_test.reset_index()\n",
    "del X_test['index']\n",
    "\n",
    "#free memory\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1 Training Model** <a id=\"31\"></a>\n",
    "\n",
    "Hyperparameter values were selected using a gridsearch with ranges of values for num_leaves, feature_fraction, bagging_fraction and min_data_in_leaf. \n",
    "\n",
    "The combination of values which resulted in the lowest validation set RMSE was selected. \n",
    "\n",
    "Learning rate is set to 0.01 as this value results in a well-behaved learning curve. Default values for other hyperparameters were deemed appropriate.\n",
    "\n",
    "The moderately sized gap between training set RMSE and validation set RMSE implies some overfitting may be occurring, however, no tweaking of hyperparameters to constrict model flexibility resulted in a lower validation RMSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lgb_model(params, X_train, X_val, y_train, y_val, cat_features):\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_val = lgb.Dataset(X_val, y_val)\n",
    "    model = lgb.train(params=params, train_set=lgb_train, valid_sets=(lgb_train, lgb_val), verbose_eval=50,\n",
    "                     categorical_feature=cat_features)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.167829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 14908\n",
      "[LightGBM] [Info] Number of data points in the train set: 7795360, number of used features: 155\n",
      "[LightGBM] [Info] Start training from score 0.312795\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[50]\ttraining's rmse: 0.978594\tvalid_1's rmse: 0.895511\n",
      "[100]\ttraining's rmse: 0.838372\tvalid_1's rmse: 0.810012\n",
      "[150]\ttraining's rmse: 0.763483\tvalid_1's rmse: 0.773514\n",
      "[200]\ttraining's rmse: 0.720879\tvalid_1's rmse: 0.756326\n",
      "[250]\ttraining's rmse: 0.693603\tvalid_1's rmse: 0.749098\n",
      "[300]\ttraining's rmse: 0.674026\tvalid_1's rmse: 0.745681\n",
      "[350]\ttraining's rmse: 0.658786\tvalid_1's rmse: 0.743695\n",
      "[400]\ttraining's rmse: 0.646359\tvalid_1's rmse: 0.742853\n",
      "[450]\ttraining's rmse: 0.635589\tvalid_1's rmse: 0.742196\n",
      "[500]\ttraining's rmse: 0.626009\tvalid_1's rmse: 0.742007\n",
      "Early stopping, best iteration is:\n",
      "[494]\ttraining's rmse: 0.627057\tvalid_1's rmse: 0.741896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x29fe01af730>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#skip this cell if directly loading saved model \n",
    "params = {\n",
    "    'objective': 'rmse',\n",
    "    'metric': 'rmse',\n",
    "    'num_leaves': 1023,\n",
    "    'min_data_in_leaf':10,\n",
    "    'feature_fraction':0.7,\n",
    "    'learning_rate': 0.01,\n",
    "    'num_rounds': 1000,\n",
    "    'early_stopping_rounds': 30,\n",
    "    'seed': 1\n",
    "}\n",
    "#designating the categorical features which should be focused on\n",
    "cat_features = ['category_id','month','shop_id','shop_city']\n",
    "\n",
    "lgb_model = build_lgb_model(params, X_train, X_val, y_train, y_val, cat_features)\n",
    "\n",
    "#save model for later use\n",
    "lgb_model.save_model('initial_lgb_model.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you wish to explore the model without retraining, it can be directly loaded by uncommenting and running the cell below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgb_model = lgb.Booster(model_file='../input/files-top-scoring-notebook-output-exploration/initial_lgb_model.txt')#\n",
    "#lgb_model.params['objective'] = 'rmse'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**3.2 Submitting** <a id=\"32\"></a>\n",
    "\n",
    "We use this model to predict on the test set, and clip the predictions into the range (0,20) before submitting. \n",
    "\n",
    "This achieves a score of 0.85389 on the public leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('C:/Users/SOGANG/Downloads/input/sample_submission.csv')\n",
    "submission['item_cnt_month'] = lgb_model.predict(X_test).clip(0,20)\n",
    "submission[['ID', 'item_cnt_month']].to_csv('initial_lgb_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Analysing Model Output<a id=\"40\"></a>\n",
    "[1. Introduction](#10)  \n",
    "[2. Preparing Dataset](#20)  \n",
    "&nbsp;&nbsp;[2.1 Preparing Item/Category Information](#21)  \n",
    "&nbsp;&nbsp;[2.2 Preparing Sales Information](#22)  \n",
    "&nbsp;&nbsp;[2.3 Constructing Training Dataframe](#23)  \n",
    "&nbsp;&nbsp;[2.4 Adding Shop Information](#24)  \n",
    "&nbsp;&nbsp;[2.5 Ages & Aggregating Sales/Price information](#25)  \n",
    "&nbsp;&nbsp;[2.6 Lagging Values & Features that use Prior Information](#26)  \n",
    "&nbsp;&nbsp;[2.7 Encoding Name Information](#27)  \n",
    "[3. Modelling](#30)  \n",
    "&nbsp;&nbsp;[3.1 Training Model](#31)  \n",
    "&nbsp;&nbsp;[3.2 Submitting](#32)  \n",
    "[4. Analysing Model Output](#40)  \n",
    "&nbsp;&nbsp;[4.1 Plots](#41)  \n",
    "&nbsp;&nbsp;[4.2 Table Views](#42)  \n",
    "\n",
    "By looking more closely at the test set and our model output, we can make adjustments to improve on our initial model. The exploration shown below can provide insights that will allow us to make beneficial changes to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "#load item/category/shop information to make analysing the results easier\n",
    "categories = pd.read_csv('input/categories.csv')\n",
    "categories['group_name'] = categories['category_name'].str.extract(r'(^[\\w\\s]*)')\n",
    "categories['group_name'] = categories['group_name'].str.strip()\n",
    "\n",
    "items = pd.read_csv('input/items.csv')\n",
    "items['item_name'] = items['item_name'].str.lower()\n",
    "for i in [r'[^\\w\\d\\s]', r'\\bthe\\b', r'\\bin\\b', r'\\bfor\\b', r'\\bof\\b', r'\\bd\\b', r'\\bis\\b', r'\\bon\\b']:\n",
    "    items['item_name'] = items['item_name'].str.replace(i, ' ')\n",
    "items['item_name'] = items['item_name'].str.replace(' ', '')\n",
    "items = items.join(categories.set_index('category_id'), on='category_id')\n",
    "\n",
    "shops = pd.read_csv('input/shops.csv')\n",
    "shops['shop_name'] = shops['shop_name'].str.lower()\n",
    "shops['shop_name'] = shops['shop_name'].str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "shops['shop_city'] = shops['shop_name'].str.split().str[0]\n",
    "shops.loc[shops['shop_id'].isin([12,55]), 'shop_city'] = 'online'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add columns showing predicted values, along with target values and sq_error for our training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['lgb_pred'] = lgb_model.predict(X_train).clip(0,20)\n",
    "X_train['target'] = y_train\n",
    "X_train['sq_err'] = (X_train['lgb_pred']-X_train['target'])**2\n",
    "\n",
    "X_val['lgb_pred'] = lgb_model.predict(X_val).clip(0,20)\n",
    "X_val['target'] = y_val\n",
    "X_val['sq_err'] = (X_val['lgb_pred']-X_val['target'])**2\n",
    "\n",
    "X_test['lgb_pred'] = lgb_model.predict(X_test).clip(0,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dataframe that will allow us to easily graph some aspects of model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X_train.groupby('date_block_num').agg({'lgb_pred':'mean','target':'mean','sq_err':'mean'}).reset_index()\n",
    "data['new_item_rmse'] = np.sqrt(X_train.query('item_age<=1').groupby('date_block_num').agg({'sq_err':'mean'}).sq_err)\n",
    "data['old_item_rmse'] = np.sqrt(X_train.query('item_age>1').groupby('date_block_num').agg({'sq_err':'mean'}).sq_err)\n",
    "data = data.append([\n",
    "    {'date_block_num':33,\n",
    "     'target':X_val.target.mean(),\n",
    "     'lgb_pred':X_val.lgb_pred.mean(),\n",
    "     'sq_err':np.sqrt(X_val.sq_err.mean()),\n",
    "     'old_item_rmse':np.sqrt(X_val.query('item_age>1').sq_err.mean()),\n",
    "     'new_item_rmse':np.sqrt(X_val.query('item_age<=1').sq_err.mean())},\n",
    "    {'date_block_num':34,\n",
    "     'target':0,\n",
    "     'lgb_pred':X_test.lgb_pred.mean(),\n",
    "     'sq_err':0,\n",
    "     'old_item_rmse':0,\n",
    "     'new_item_rmse':0}\n",
    "    ],\n",
    "    ignore_index=True\n",
    ")\n",
    "data['date'] = [x[:7] for x in pd.date_range(start='2013-03',end='2015-09',freq='MS').astype('str')]+['Validation','Test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1 Plots** <a id=\"41\"></a>\n",
    "\n",
    "A summary plot of feature importance. We can use this along with other [shap](https://shap.readthedocs.io/en/latest/) plots to get an idea of what drives the models predictions, and help us find spurious features which can be filtered out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = X_test.drop(columns='lgb_pred').sample(10000)\n",
    "explainer = shap.TreeExplainer(lgb_model)\n",
    "shap_values = explainer.shap_values(temp)\n",
    "shap.summary_plot(shap_values, temp, max_display=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='Prediction',x=data.date,y=data.lgb_pred),\n",
    "    go.Bar(name='Target',x=data.date,y=data.target)\n",
    "])\n",
    "fig.update_layout(\n",
    "    title='Mean Prediction and Target Values by Month',\n",
    "    xaxis={'title':'Month','type':'category'},\n",
    "    yaxis={'title':'Mean Value'},\n",
    "    legend={'yanchor':'top','y':1.05,'xanchor':'left','x':0.01},\n",
    "    template='plotly_dark'\n",
    ")\n",
    "\n",
    "text = '''\n",
    "    The model may not be adequately accounting for<br>\n",
    "    the December sales spike. There is no systemic under or<br>\n",
    "    over-prediction visible for the test month, November.\n",
    "'''\n",
    "fig.add_annotation(\n",
    "    yref='paper', y=1.1,\n",
    "    xref='paper', x=0.7,\n",
    "    text=text,\n",
    "    font={'size':11},\n",
    "    showarrow=False)\n",
    "\n",
    "text = '''\n",
    "    Prediction mean is very close to the  <br> \n",
    "    target mean in our validation set.\n",
    "'''\n",
    "fig.add_annotation(\n",
    "    xref='paper', x=0.95,\n",
    "    yref='paper', y=0.58,\n",
    "    text=text,\n",
    "    font={'size':11},\n",
    "    showarrow=True, arrowhead=1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Bar(\n",
    "    x=data.date[:-1],\n",
    "    y=data.sq_err[:-1],\n",
    "    marker_color=[x%12 for x in range(2,34)]\n",
    ")])\n",
    "fig.update_layout(\n",
    "    title='RMSE by Month',\n",
    "    xaxis={'title':'Month','type':'category'},\n",
    "    yaxis={'title':'RMSE'},\n",
    "    template='plotly_dark'\n",
    ")\n",
    "text = '''\n",
    "    In the training set, RMSE is highest in December. <br>\n",
    "    \n",
    "'''\n",
    "fig.add_annotation(\n",
    "    yref='paper', y=0.9,\n",
    "    xref='paper', x=0.1,\n",
    "    text=text,\n",
    "    font={'size':11},\n",
    "    showarrow=False)\n",
    "text = '''\n",
    "    Validation RMSE is higher than in any month of <br>\n",
    "    the training set. This is expected given the <br>\n",
    "    gap in training set and validation set RMSE we <br>\n",
    "    saw when training the model.\n",
    "'''\n",
    "fig.add_annotation(\n",
    "    yref='paper', y=1.1,\n",
    "    xref='paper', x=1,\n",
    "    text=text,\n",
    "    font={'size':11},\n",
    "    showarrow=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "temp = X_val.groupby('item_age').agg({'sq_err':'mean','target':'mean'}).reset_index()\n",
    "temp['sq_err'] = np.sqrt(temp['sq_err'])\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='RMSE',x=temp.item_age,y=temp.sq_err)\n",
    "])\n",
    "fig.update_layout(\n",
    "    title='Validation set RMSE by Item Age',\n",
    "    xaxis={'title':'Item Age','type':'category'},\n",
    "    yaxis={'title':'RMSE'},\n",
    "    template='plotly_dark'\n",
    ")\n",
    "text = '''\n",
    "    RMSE is much higher for items with age 0 or 1. There is a <br>\n",
    "    sharp decrease in RMSE between ages 0 and 2, then a much <br>\n",
    "    flatter downwards trend as age increases beyond 2.\n",
    "'''\n",
    "fig.add_annotation(\n",
    "    yref='paper', y=0.8,\n",
    "    xref='paper', x=0.04,\n",
    "    text=text,\n",
    "    font={'size':11},\n",
    "    showarrow=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='Item Age <=1 RMSE',x=data.date[:-1],y=data.new_item_rmse[:-1]),\n",
    "    go.Bar(name='Item Age > 1 RMSE',x=data.date[:-1],y=data.old_item_rmse[:-1])\n",
    "])\n",
    "fig.update_layout(\n",
    "    title='RMSE by Month for New and Old Items',\n",
    "    xaxis={'title':'Month','type':'category'},\n",
    "    yaxis={'title':'Mean Value'},\n",
    "    legend={'yanchor':'top','y':1.05,'xanchor':'left','x':0.01},\n",
    "    template='plotly_dark'\n",
    ")\n",
    "text = '''\n",
    "    For older items, performance on the validation set is no worse than <br>\n",
    "    performance on the training set. The higher overall validation set <br>\n",
    "    RMSE is caused by a significantly higher RMSE for new items.\n",
    "'''\n",
    "fig.add_annotation(yref='paper', y=1.1,\n",
    "                   xref='paper', x=0.93,\n",
    "                   text=text,\n",
    "                   font={'size':11},\n",
    "                   showarrow=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2 Table Views** <a id=\"42\"></a>\n",
    "\n",
    "There are 42 shops in our dataset. The following view shows us which shops have previously sold any items from each category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../input/files-top-scoring-notebook-output-exploration/df_complete.pkl')\n",
    "(\n",
    "df\n",
    "[df['category_id'].isin(X_test.category_id.unique())]\n",
    ".query('item_cnt>0')\n",
    ".groupby('category_id')\n",
    ".agg({\n",
    "    'category_age':'max',\n",
    "    'shop_id':['nunique','unique'],\n",
    "    'item_cnt':'sum'\n",
    "    })\n",
    ".join(categories['category_name'])\n",
    ".join(\n",
    "    X_test       \n",
    "    .groupby('category_id')\n",
    "    .agg({'item_id':'nunique'})\n",
    "    .rename(columns={'item_id':'test_set_items'})\n",
    ")\n",
    ".sort_values(('shop_id', 'nunique'))\n",
    ".head(20)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following view shows which shops are causing the most loss in our validation set. Shops 25, 31, 42, and 28 have the highest MSEs but also the highest target means (we would expect to see MSE scale with target mean). Shops 12 and 55 have the next highest MSEs, and do not have relatively high target means. These are the only two shops which have a category only they sell. Could they benefit from being segregated in the training stage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "X_val\n",
    "[X_val['category_id'].isin(X_test.category_id.unique())]\n",
    ".groupby('shop_id')\n",
    ".agg({\n",
    "    'sq_err':'mean',\n",
    "    'target':'mean',\n",
    "    'lgb_pred':'mean'\n",
    "})\n",
    ".join(\n",
    "    X_test\n",
    "    .rename(columns={'lgb_pred':'test_pred'})\n",
    "    .groupby('shop_id')\n",
    "    .agg({'test_pred':'mean'})\n",
    ")\n",
    ".join(shops['shop_name'])\n",
    ".sort_values('sq_err', ascending=False)\n",
    ".head(20)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following view shows which categories are causing the most loss in our validation set, and how prominent these categories are within the test set. Looking at their MSE and presence in the test set shows us that the video game categories are the causing the most loss and might warrant especially close examination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "X_val\n",
    "[X_val['category_id'].isin(X_test.category_id.unique())]\n",
    ".groupby('category_id')\n",
    ".agg({\n",
    "    'sq_err':['sum','mean'],\n",
    "    'target':'mean',\n",
    "    'lgb_pred':['sum','mean'],\n",
    "    'item_id':'nunique'\n",
    "})\n",
    ".join(\n",
    "    X_test\n",
    "    .rename(columns={'lgb_pred':'test_pred','item_id':'test_items'})\n",
    "    .groupby('category_id')        \n",
    "    .agg({\n",
    "        'test_pred':['sum','mean'],\n",
    "        'test_items':'nunique'\n",
    "    }),\n",
    "    on='category_id'\n",
    ")\n",
    ".join(categories)\n",
    ".sort_values(('sq_err', 'mean'), ascending=False)\n",
    ".head(20)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following view shows which items have the least accurate predictions across all shops in the validation set. Changing the value of the CATEGORY variable will allow you to look through different categories of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#edit this value to look through the biggest problem items in each category\n",
    "CATEGORY = 20\n",
    "(\n",
    "items[\n",
    "    items['item_id'].isin(X_val.item_id.unique()) & \n",
    "    items['item_id'].isin(X_test.item_id.unique())\n",
    "]\n",
    "[['category_id','category_name','item_id','item_name']]\n",
    ".join(\n",
    "    X_test\n",
    "    .rename(columns={'lgb_pred':'test_pred'})\n",
    "    .groupby('item_id')        \n",
    "    .agg({'test_pred':'mean'}),\n",
    "    on='item_id'\n",
    ")\n",
    ".join(\n",
    "    X_val\n",
    "    .groupby('item_id')\n",
    "    .agg({\n",
    "        'lgb_pred':'mean',\n",
    "        'target':'mean',\n",
    "        'sq_err':'mean',\n",
    "        'same_name4catage_cnt_all_shops':'first',\n",
    "        'new_items_in_cat_all_shops_lag1to12':'first',\n",
    "        'item_cnt_all_shops_lag1':'first',\n",
    "        'category_cnt_all_shops_lag1':'first',\n",
    "        'item_cnt_sum_alltime_allshops':'first',\n",
    "        'prev_days_on_sale':'first'\n",
    "    })\n",
    "    .rename(columns={\n",
    "        'lgb_pred':'val_pred',\n",
    "        'target':'val_target',  \n",
    "    }),\n",
    "    on='item_id'\n",
    ")\n",
    ".query(f'category_id=={CATEGORY}')\n",
    ".sort_values('sq_err',ascending=False)\n",
    ".rename(columns={\n",
    "    'same_name4catage_cnt_all_shops':'name4mean',\n",
    "    'new_items_in_cat_all_shops_lag1to12':'new_in_cat_mean',\n",
    "    'item_cnt_all_shops_lag1':'item_cnt_lag1',\n",
    "    'category_cnt_all_shops_lag1':'cat_cnt_lag1',\n",
    "    'category_id':'cat',\n",
    "    'item_cnt_sum_alltime_allshops':'item_cnt_alltime'\n",
    "})\n",
    ".head(20)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following view shows which items in each category have the highest prediction value across all shops in the test set. Again the CATEGORY variable can be changed to look through different categories of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORY = 20  \n",
    "(\n",
    "items[items['item_id'].isin(X_test.item_id.unique())]\n",
    "[['category_id','category_name','item_id','item_name']]\n",
    ".join(\n",
    "    X_test\n",
    "    .groupby('item_id')\n",
    "    .agg({\n",
    "        'lgb_pred':'mean',\n",
    "        'same_name4catage_cnt_all_shops':'first',\n",
    "        'new_items_in_cat_all_shops_lag1to12':'first',\n",
    "        'item_cnt_all_shops_lag1':'first',\n",
    "        'category_cnt_all_shops_lag1':'first',\n",
    "        'item_cnt_sum_alltime_allshops':'first',\n",
    "        'prev_days_on_sale':'first'\n",
    "    })\n",
    "    .rename(columns={'lgb_pred':'test_pred'}),\n",
    "    on='item_id'\n",
    ")\n",
    ".query(f'category_id=={CATEGORY}')\n",
    ".sort_values('test_pred',ascending=False)\n",
    ".rename(columns={\n",
    "     'same_name4catage_cnt_all_shops':'name4mean',\n",
    "     'new_items_in_cat_all_shops_lag1to12':'new_in_cat_mean',\n",
    "     'item_cnt_all_shops_lag1':'item_cnt_lag1',\n",
    "     'category_cnt_all_shops_lag1':'cat_cnt_lag1',\n",
    "     'item_category_id':'cat',\n",
    "     'item_cnt_sum_alltime_allshops':'item_cnt_alltime'\n",
    "})\n",
    ".head(20)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these final two views in tandem can help identify specific problematic items in the test set. It is easier to keep track of the information when all the columns can be seen at once in the wider view available when running the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
